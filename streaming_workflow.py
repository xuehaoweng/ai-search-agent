import asyncio
import json
import time
from typing import Dict, List, Optional, Any, AsyncGenerator, Callable, Union
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum
import uuid

from schemas import StreamChunk, SearchConfig, SearchType
from stateful_agent import StatefulSearchAgent, ConversationManager

class WorkflowStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class WorkflowStep:
    """å·¥ä½œæµæ­¥éª¤"""
    step_id: str
    name: str
    function: Callable
    params: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    status: WorkflowStatus = WorkflowStatus.PENDING
    result: Optional[Any] = None
    error: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    
    @property
    def duration(self) -> Optional[float]:
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None

@dataclass
class Workflow:
    """å·¥ä½œæµå®šä¹‰"""
    workflow_id: str
    name: str
    steps: List[WorkflowStep] = field(default_factory=list)
    status: WorkflowStatus = WorkflowStatus.PENDING
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    
    @property
    def total_duration(self) -> Optional[float]:
        if self.started_at and self.completed_at:
            return (self.completed_at - self.started_at).total_seconds()
        return None

class StreamingWorkflowEngine:
    """æµå¼å·¥ä½œæµå¼•æ“"""
    
    def __init__(self, conversation_manager: ConversationManager):
        self.conversation_manager = conversation_manager
        self.active_workflows: Dict[str, Workflow] = {}
        self.workflow_templates: Dict[str, Callable] = {}
        
        # æ³¨å†Œé»˜è®¤å·¥ä½œæµæ¨¡æ¿
        self._register_default_templates()
    
    def _register_default_templates(self):
        """æ³¨å†Œé»˜è®¤å·¥ä½œæµæ¨¡æ¿"""
        self.workflow_templates.update({
            "comprehensive_search": self._create_comprehensive_search_workflow,
            "multi_source_analysis": self._create_multi_source_analysis_workflow,
            "research_report": self._create_research_report_workflow,
            "competitive_analysis": self._create_competitive_analysis_workflow,
            "trend_analysis": self._create_trend_analysis_workflow
        })
    
    async def execute_workflow_stream(self, 
                                    workflow_template: str,
                                    params: Dict[str, Any],
                                    agent_id: str,
                                    conversation_id: Optional[str] = None) -> AsyncGenerator[StreamChunk, None]:
        """æ‰§è¡Œå·¥ä½œæµå¹¶è¿”å›æµå¼ç»“æœ"""
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow = await self._create_workflow(workflow_template, params)
        self.active_workflows[workflow.workflow_id] = workflow
        
        # è·å–ä»£ç†
        agent = self.conversation_manager.get_agent(agent_id)
        if not agent:
            yield StreamChunk(
                chunk_type="complete",
                content={"error": f"Agent {agent_id} not found"},
                chunk_id=f"error_{int(time.time())}"
            )
            return
        
        try:
            workflow.status = WorkflowStatus.RUNNING
            workflow.started_at = datetime.now()
            
            # å‘é€å¼€å§‹ä¿¡å·
            yield StreamChunk(
                chunk_type="text",
                content=f"ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow.name}",
                chunk_id=f"start_{workflow.workflow_id}"
            )
            
            # æ‰§è¡Œå·¥ä½œæµæ­¥éª¤
            async for chunk in self._execute_workflow_steps(workflow, agent, conversation_id):
                yield chunk
            
            workflow.status = WorkflowStatus.COMPLETED
            workflow.completed_at = datetime.now()
            
            # å‘é€å®Œæˆä¿¡å·
            yield StreamChunk(
                chunk_type="complete",
                content={
                    "workflow_id": workflow.workflow_id,
                    "status": workflow.status.value,
                    "duration": workflow.total_duration,
                    "steps_completed": len([s for s in workflow.steps if s.status == WorkflowStatus.COMPLETED])
                },
                chunk_id=f"complete_{workflow.workflow_id}"
            )
            
        except Exception as e:
            workflow.status = WorkflowStatus.FAILED
            yield StreamChunk(
                chunk_type="complete",
                content={"error": f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}"},
                chunk_id=f"error_{workflow.workflow_id}"
            )
        finally:
            # æ¸…ç†å®Œæˆçš„å·¥ä½œæµ
            if workflow.workflow_id in self.active_workflows:
                del self.active_workflows[workflow.workflow_id]
    
    async def _create_workflow(self, template_name: str, params: Dict[str, Any]) -> Workflow:
        """åˆ›å»ºå·¥ä½œæµå®ä¾‹"""
        if template_name not in self.workflow_templates:
            raise ValueError(f"Unknown workflow template: {template_name}")
        
        workflow_id = str(uuid.uuid4())
        creator = self.workflow_templates[template_name]
        return creator(workflow_id, params)
    
    async def _execute_workflow_steps(self, 
                                    workflow: Workflow, 
                                    agent: StatefulSearchAgent,
                                    conversation_id: Optional[str]) -> AsyncGenerator[StreamChunk, None]:
        """æ‰§è¡Œå·¥ä½œæµæ­¥éª¤"""
        
        # æ„å»ºä¾èµ–å›¾
        dependency_graph = self._build_dependency_graph(workflow.steps)
        
        # æ‰§è¡Œæ­¥éª¤
        completed_steps = set()
        step_results = {}
        
        while len(completed_steps) < len(workflow.steps):
            # æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„æ­¥éª¤
            ready_steps = []
            for step in workflow.steps:
                if (step.step_id not in completed_steps and 
                    step.status == WorkflowStatus.PENDING and
                    all(dep in completed_steps for dep in step.dependencies)):
                    ready_steps.append(step)
            
            if not ready_steps:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¾ªç¯ä¾èµ–æˆ–å…¶ä»–é—®é¢˜
                pending_steps = [s for s in workflow.steps if s.status == WorkflowStatus.PENDING]
                if pending_steps:
                    raise RuntimeError("Workflow deadlock detected - circular dependencies or missing steps")
                break
            
            # å¹¶è¡Œæ‰§è¡Œå‡†å¤‡å¥½çš„æ­¥éª¤
            tasks = []
            for step in ready_steps:
                task = asyncio.create_task(
                    self._execute_step(step, agent, conversation_id, step_results)
                )
                tasks.append((step, task))
            
            # ç­‰å¾…æ­¥éª¤å®Œæˆå¹¶å‘é€æµå¼æ›´æ–°
            for step, task in tasks:
                try:
                    yield StreamChunk(
                        chunk_type="text",
                        content=f"âš™ï¸ æ‰§è¡Œæ­¥éª¤: {step.name}",
                        chunk_id=f"step_{step.step_id}"
                    )
                    
                    result = await task
                    step.result = result
                    step.status = WorkflowStatus.COMPLETED
                    step_results[step.step_id] = result
                    completed_steps.add(step.step_id)
                    
                    yield StreamChunk(
                        chunk_type="result",
                        content={
                            "step_id": step.step_id,
                            "step_name": step.name,
                            "result": result,
                            "duration": step.duration
                        },
                        chunk_id=f"result_{step.step_id}"
                    )
                    
                except Exception as e:
                    step.status = WorkflowStatus.FAILED
                    step.error = str(e)
                    
                    yield StreamChunk(
                        chunk_type="result",
                        content={
                            "step_id": step.step_id,
                            "step_name": step.name,
                            "error": str(e)
                        },
                        chunk_id=f"error_{step.step_id}"
                    )
    
    def _build_dependency_graph(self, steps: List[WorkflowStep]) -> Dict[str, List[str]]:
        """æ„å»ºä¾èµ–å›¾"""
        graph = {}
        for step in steps:
            graph[step.step_id] = step.dependencies
        return graph
    
    async def _execute_step(self, 
                          step: WorkflowStep, 
                          agent: StatefulSearchAgent,
                          conversation_id: Optional[str],
                          previous_results: Dict[str, Any]) -> Any:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        step.status = WorkflowStatus.RUNNING
        step.start_time = datetime.now()
        
        try:
            # å‡†å¤‡å‚æ•°
            params = step.params.copy()
            params['agent'] = agent
            params['conversation_id'] = conversation_id
            params['previous_results'] = previous_results
            
            # æ‰§è¡Œæ­¥éª¤å‡½æ•°
            result = await step.function(**params)
            
            step.end_time = datetime.now()
            return result
            
        except Exception as e:
            step.end_time = datetime.now()
            step.error = str(e)
            raise
    
    # å·¥ä½œæµæ¨¡æ¿åˆ›å»ºæ–¹æ³•
    def _create_comprehensive_search_workflow(self, workflow_id: str, params: Dict[str, Any]) -> Workflow:
        """åˆ›å»ºç»¼åˆæœç´¢å·¥ä½œæµ"""
        query = params.get('query', '')
        
        steps = [
            WorkflowStep(
                step_id="search_general",
                name="é€šç”¨æœç´¢",
                function=self._search_step,
                params={"query": query, "search_type": "general"}
            ),
            WorkflowStep(
                step_id="search_news",
                name="æ–°é—»æœç´¢",
                function=self._search_step,
                params={"query": query, "search_type": "news"}
            ),
            WorkflowStep(
                step_id="search_academic",
                name="å­¦æœ¯æœç´¢",
                function=self._search_step,
                params={"query": query, "search_type": "academic"}
            ),
            WorkflowStep(
                step_id="synthesize_results",
                name="ç»“æœç»¼åˆ",
                function=self._synthesize_step,
                params={"query": query},
                dependencies=["search_general", "search_news", "search_academic"]
            ),
            WorkflowStep(
                step_id="generate_summary",
                name="ç”Ÿæˆæ‘˜è¦",
                function=self._summary_step,
                params={},
                dependencies=["synthesize_results"]
            )
        ]
        
        return Workflow(
            workflow_id=workflow_id,
            name="ç»¼åˆæœç´¢åˆ†æ",
            steps=steps
        )
    
    def _create_multi_source_analysis_workflow(self, workflow_id: str, params: Dict[str, Any]) -> Workflow:
        """åˆ›å»ºå¤šæºåˆ†æå·¥ä½œæµ"""
        topic = params.get('topic', '')
        
        steps = [
            WorkflowStep(
                step_id="collect_sources",
                name="æ”¶é›†ä¿¡æ¯æº",
                function=self._collect_sources_step,
                params={"topic": topic}
            ),
            WorkflowStep(
                step_id="analyze_sentiment",
                name="æƒ…æ„Ÿåˆ†æ",
                function=self._sentiment_analysis_step,
                params={},
                dependencies=["collect_sources"]
            ),
            WorkflowStep(
                step_id="extract_key_points",
                name="æå–å…³é”®ç‚¹",
                function=self._extract_key_points_step,
                params={},
                dependencies=["collect_sources"]
            ),
            WorkflowStep(
                step_id="cross_reference",
                name="äº¤å‰å¼•ç”¨",
                function=self._cross_reference_step,
                params={},
                dependencies=["analyze_sentiment", "extract_key_points"]
            ),
            WorkflowStep(
                step_id="generate_report",
                name="ç”ŸæˆæŠ¥å‘Š",
                function=self._generate_report_step,
                params={"topic": topic},
                dependencies=["cross_reference"]
            )
        ]
        
        return Workflow(
            workflow_id=workflow_id,
            name="å¤šæºä¿¡æ¯åˆ†æ",
            steps=steps
        )
    
    def _create_research_report_workflow(self, workflow_id: str, params: Dict[str, Any]) -> Workflow:
        """åˆ›å»ºç ”ç©¶æŠ¥å‘Šå·¥ä½œæµ"""
        topic = params.get('topic', '')
        
        steps = [
            WorkflowStep(
                step_id="literature_review",
                name="æ–‡çŒ®ç»¼è¿°",
                function=self._literature_review_step,
                params={"topic": topic}
            ),
            WorkflowStep(
                step_id="current_trends",
                name="å½“å‰è¶‹åŠ¿åˆ†æ",
                function=self._trends_analysis_step,
                params={"topic": topic}
            ),
            WorkflowStep(
                step_id="expert_opinions",
                name="ä¸“å®¶è§‚ç‚¹æ”¶é›†",
                function=self._expert_opinions_step,
                params={"topic": topic}
            ),
            WorkflowStep(
                step_id="market_analysis",
                name="å¸‚åœºåˆ†æ",
                function=self._market_analysis_step,
                params={"topic": topic},
                dependencies=["current_trends"]
            ),
            WorkflowStep(
                step_id="compile_report",
                name="ç¼–è¯‘æŠ¥å‘Š",
                function=self._compile_report_step,
                params={"topic": topic},
                dependencies=["literature_review", "current_trends", "expert_opinions", "market_analysis"]
            )
        ]
        
        return Workflow(
            workflow_id=workflow_id,
            name="ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ",
            steps=steps
        )
    
    def _create_competitive_analysis_workflow(self, workflow_id: str, params: Dict[str, Any]) -> Workflow:
        """åˆ›å»ºç«äº‰åˆ†æå·¥ä½œæµ"""
        company = params.get('company', '')
        industry = params.get('industry', '')
        
        steps = [
            WorkflowStep(
                step_id="company_profile",
                name="å…¬å¸æ¦‚å†µ",
                function=self._company_profile_step,
                params={"company": company}
            ),
            WorkflowStep(
                step_id="competitor_identification",
                name="ç«äº‰å¯¹æ‰‹è¯†åˆ«",
                function=self._competitor_identification_step,
                params={"company": company, "industry": industry}
            ),
            WorkflowStep(
                step_id="market_position",
                name="å¸‚åœºå®šä½åˆ†æ",
                function=self._market_position_step,
                params={"company": company},
                dependencies=["company_profile", "competitor_identification"]
            ),
            WorkflowStep(
                step_id="swot_analysis",
                name="SWOTåˆ†æ",
                function=self._swot_analysis_step,
                params={"company": company},
                dependencies=["market_position"]
            ),
            WorkflowStep(
                step_id="strategic_recommendations",
                name="æˆ˜ç•¥å»ºè®®",
                function=self._strategic_recommendations_step,
                params={"company": company},
                dependencies=["swot_analysis"]
            )
        ]
        
        return Workflow(
            workflow_id=workflow_id,
            name="ç«äº‰åˆ†ææŠ¥å‘Š",
            steps=steps
        )
    
    def _create_trend_analysis_workflow(self, workflow_id: str, params: Dict[str, Any]) -> Workflow:
        """åˆ›å»ºè¶‹åŠ¿åˆ†æå·¥ä½œæµ"""
        domain = params.get('domain', '')
        timeframe = params.get('timeframe', '1year')
        
        steps = [
            WorkflowStep(
                step_id="historical_data",
                name="å†å²æ•°æ®æ”¶é›†",
                function=self._historical_data_step,
                params={"domain": domain, "timeframe": timeframe}
            ),
            WorkflowStep(
                step_id="pattern_recognition",
                name="æ¨¡å¼è¯†åˆ«",
                function=self._pattern_recognition_step,
                params={},
                dependencies=["historical_data"]
            ),
            WorkflowStep(
                step_id="emerging_trends",
                name="æ–°å…´è¶‹åŠ¿è¯†åˆ«",
                function=self._emerging_trends_step,
                params={"domain": domain}
            ),
            WorkflowStep(
                step_id="trend_correlation",
                name="è¶‹åŠ¿å…³è”åˆ†æ",
                function=self._trend_correlation_step,
                params={},
                dependencies=["pattern_recognition", "emerging_trends"]
            ),
            WorkflowStep(
                step_id="future_projection",
                name="æœªæ¥é¢„æµ‹",
                function=self._future_projection_step,
                params={"domain": domain},
                dependencies=["trend_correlation"]
            )
        ]
        
        return Workflow(
            workflow_id=workflow_id,
            name="è¶‹åŠ¿åˆ†ææŠ¥å‘Š",
            steps=steps
        )
    
    # æ­¥éª¤æ‰§è¡Œå‡½æ•°
    async def _search_step(self, query: str, search_type: str, agent: StatefulSearchAgent, **kwargs) -> Dict[str, Any]:
        """æœç´¢æ­¥éª¤"""
        config = SearchConfig(
            search_type=SearchType(search_type),
            max_results=10,
            include_summary=True
        )
        result = await agent.search_tools.smart_search(query, config)
        return result.dict()
    
    async def _synthesize_step(self, query: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """ç»“æœç»¼åˆæ­¥éª¤"""
        # ç»¼åˆå¤šä¸ªæœç´¢ç»“æœ
        all_results = []
        for step_id, result in previous_results.items():
            if isinstance(result, dict) and 'results' in result:
                all_results.extend(result['results'])
        
        return {
            "query": query,
            "total_results": len(all_results),
            "synthesized_results": all_results[:20],  # å–å‰20ä¸ªç»“æœ
            "summary": f"ç»¼åˆäº† {len(all_results)} ä¸ªæœç´¢ç»“æœ"
        }
    
    async def _summary_step(self, previous_results: Dict[str, Any], agent: StatefulSearchAgent, **kwargs) -> Dict[str, Any]:
        """æ‘˜è¦ç”Ÿæˆæ­¥éª¤"""
        synthesized = previous_results.get('synthesize_results', {})
        summary_text = synthesized.get('summary', '')
        
        if summary_text:
            result = await agent.summary_tool.summarize_text(summary_text, 300)
            return result.dict()
        
        return {"summary": "æ— æ³•ç”Ÿæˆæ‘˜è¦"}
    
    # å…¶ä»–æ­¥éª¤å‡½æ•°çš„ç®€åŒ–å®ç°
    async def _collect_sources_step(self, topic: str, **kwargs) -> Dict[str, Any]:
        return {"topic": topic, "sources": ["source1", "source2", "source3"]}
    
    async def _sentiment_analysis_step(self, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"sentiment": "neutral", "confidence": 0.7}
    
    async def _extract_key_points_step(self, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"key_points": ["point1", "point2", "point3"]}
    
    async def _cross_reference_step(self, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"cross_references": ["ref1", "ref2"]}
    
    async def _generate_report_step(self, topic: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"report": f"å…³äº{topic}çš„åˆ†ææŠ¥å‘Š", "sections": ["introduction", "analysis", "conclusion"]}
    
    async def _literature_review_step(self, topic: str, **kwargs) -> Dict[str, Any]:
        return {"literature_count": 50, "key_papers": ["paper1", "paper2"]}
    
    async def _trends_analysis_step(self, topic: str, **kwargs) -> Dict[str, Any]:
        return {"trends": ["trend1", "trend2"], "growth_rate": "15%"}
    
    async def _expert_opinions_step(self, topic: str, **kwargs) -> Dict[str, Any]:
        return {"experts": ["expert1", "expert2"], "opinions": ["opinion1", "opinion2"]}
    
    async def _market_analysis_step(self, topic: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"market_size": "1B", "growth_potential": "high"}
    
    async def _compile_report_step(self, topic: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"final_report": f"å®Œæ•´çš„{topic}ç ”ç©¶æŠ¥å‘Š", "page_count": 25}
    
    async def _company_profile_step(self, company: str, **kwargs) -> Dict[str, Any]:
        return {"company": company, "revenue": "1B", "employees": 1000}
    
    async def _competitor_identification_step(self, company: str, industry: str, **kwargs) -> Dict[str, Any]:
        return {"competitors": ["comp1", "comp2", "comp3"], "industry": industry}
    
    async def _market_position_step(self, company: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"market_share": "15%", "position": "leader"}
    
    async def _swot_analysis_step(self, company: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {
            "strengths": ["strength1", "strength2"],
            "weaknesses": ["weakness1"],
            "opportunities": ["opportunity1"],
            "threats": ["threat1"]
        }
    
    async def _strategic_recommendations_step(self, company: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"recommendations": ["rec1", "rec2", "rec3"]}
    
    async def _historical_data_step(self, domain: str, timeframe: str, **kwargs) -> Dict[str, Any]:
        return {"data_points": 365, "timeframe": timeframe, "domain": domain}
    
    async def _pattern_recognition_step(self, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"patterns": ["pattern1", "pattern2"], "confidence": 0.8}
    
    async def _emerging_trends_step(self, domain: str, **kwargs) -> Dict[str, Any]:
        return {"emerging_trends": ["trend1", "trend2"], "domain": domain}
    
    async def _trend_correlation_step(self, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"correlations": [{"trend1": "trend2", "correlation": 0.7}]}
    
    async def _future_projection_step(self, domain: str, previous_results: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        return {"projection": "å¢é•¿è¶‹åŠ¿", "confidence": 0.6, "timeframe": "next_year"}
    
    def get_workflow_status(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        if workflow_id not in self.active_workflows:
            return None
        
        workflow = self.active_workflows[workflow_id]
        return {
            "workflow_id": workflow_id,
            "name": workflow.name,
            "status": workflow.status.value,
            "created_at": workflow.created_at.isoformat(),
            "started_at": workflow.started_at.isoformat() if workflow.started_at else None,
            "completed_at": workflow.completed_at.isoformat() if workflow.completed_at else None,
            "duration": workflow.total_duration,
            "steps": [
                {
                    "step_id": step.step_id,
                    "name": step.name,
                    "status": step.status.value,
                    "duration": step.duration,
                    "error": step.error
                }
                for step in workflow.steps
            ]
        }
    
    def list_workflow_templates(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨çš„å·¥ä½œæµæ¨¡æ¿"""
        return list(self.workflow_templates.keys())

# å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
class AsyncTaskQueue:
    """å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—"""
    
    def __init__(self, max_concurrent_tasks: int = 5):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.queue = asyncio.Queue()
        self.running_tasks = set()
        self.completed_tasks = {}
        self.failed_tasks = {}
        self._worker_tasks = []
    
    async def start_workers(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        for i in range(self.max_concurrent_tasks):
            task = asyncio.create_task(self._worker(f"worker_{i}"))
            self._worker_tasks.append(task)
    
    async def stop_workers(self):
        """åœæ­¢å·¥ä½œçº¿ç¨‹"""
        for task in self._worker_tasks:
            task.cancel()
        await asyncio.gather(*self._worker_tasks, return_exceptions=True)
        self._worker_tasks.clear()
    
    async def _worker(self, worker_name: str):
        """å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                task_item = await self.queue.get()
                task_id, coro = task_item
                
                self.running_tasks.add(task_id)
                
                try:
                    result = await coro
                    self.completed_tasks[task_id] = result
                except Exception as e:
                    self.failed_tasks[task_id] = str(e)
                finally:
                    self.running_tasks.discard(task_id)
                    self.queue.task_done()
                    
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"Worker {worker_name} error: {e}")
    
    async def submit_task(self, task_id: str, coro) -> str:
        """æäº¤ä»»åŠ¡"""
        await self.queue.put((task_id, coro))
        return task_id
    
    def get_task_status(self, task_id: str) -> str:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        if task_id in self.completed_tasks:
            return "completed"
        elif task_id in self.failed_tasks:
            return "failed"
        elif task_id in self.running_tasks:
            return "running"
        else:
            return "pending"
    
    def get_task_result(self, task_id: str) -> Optional[Any]:
        """è·å–ä»»åŠ¡ç»“æœ"""
        return self.completed_tasks.get(task_id)
    
    def get_task_error(self, task_id: str) -> Optional[str]:
        """è·å–ä»»åŠ¡é”™è¯¯"""
        return self.failed_tasks.get(task_id)